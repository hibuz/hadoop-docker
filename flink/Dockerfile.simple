# == Info =======================================
# hibuz/bash==hibuz/hadoop-base(SIZE: 292MB) -> hibuz/hadoop-dev(SIZE: 3.53GB)

# == Build ======================================
# docker build -t hibuz/hadoop-dev:jdk21 ../ --build-arg JDK_VERSION=21
# docker build -t hibuz/flink-dev:simple -f Dockerfile.simple .

# == Run and Attatch ============================
# docker run --rm -it -p 8083:8083 --name flink-tmp hibuz/flink-dev:simple
# 
# docker exec -it flink-tmp bash


# == Init =======================================
ARG JDK_VERSION=21
FROM hibuz/hadoop-dev:jdk${JDK_VERSION}
LABEL org.opencontainers.image.authors="hibuz@hibuz.com"

# == Install ============================
ARG SPARK_VERSION=4.1.0-preview1
ENV SPARK_HOME=/home/${DEFAULT_USER}/spark-${SPARK_VERSION}

RUN set -x \
    && DOWNLOAD_URL="https://dlcdn.apache.org/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-without-hadoop.tgz" \
    && curl -fSL "$DOWNLOAD_URL" -o download.tar.gz \
    && tar -xvf download.tar.gz \
    && mv spark-${SPARK_VERSION}-bin-* $SPARK_HOME \
    && mkdir /tmp/spark-events \
    && rm download.tar.gz

ENV PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin

RUN cp $SPARK_HOME/conf/spark-env.sh.template $SPARK_HOME/conf/spark-env.sh \
    && echo "export HADOOP_HOME=$HADOOP_HOME" >> $SPARK_HOME/conf/spark-env.sh \
    && echo "export SPARK_DIST_CLASSPATH=\$(\$HADOOP_HOME/bin/hadoop classpath)" >> $SPARK_HOME/conf/spark-env.sh

# == Install ============================
ARG HIVE_VERSION=4.1.0
ENV HIVE_HOME=/home/${DEFAULT_USER}/hive-${HIVE_VERSION}

RUN set -x \
    && DOWNLOAD_URL="https://dlcdn.apache.org/hive/hive-${HIVE_VERSION}/apache-hive-${HIVE_VERSION}-bin.tar.gz" \
    && curl -fSL "$DOWNLOAD_URL" -o download.tar.gz \
    && tar -xvf download.tar.gz \
    && mv apache-hive-${HIVE_VERSION}-bin $HIVE_HOME \
    && rm download.tar.gz

ENV PATH=$PATH:$HIVE_HOME/bin

RUN mv $SPARK_HOME/bin/beeline $SPARK_HOME/bin/spark-beeline \
    && cp $HIVE_HOME/conf/hive-env.sh.template $HIVE_HOME/conf/hive-env.sh \
    && echo "export HADOOP_HEAPSIZE=512" >> $HIVE_HOME/conf/hive-env.sh \
    && cp $HIVE_HOME/conf/hive-default.xml.template $HIVE_HOME/conf/hive-site.xml

RUN core_conf="<property><name>system:java.io.tmpdir</name><value>/tmp/hive/java</value></property>\
                <property><name>system:user.name</name><value>${DEFAULT_USER}</value></property>\
                <property><name>hive.metastore.uris</name><value>thrift://localhost:9083</value></property>" \
    && escaped_core_conf=$(echo $core_conf | sed 's/\//\\\//g') \
    && sed -i "/<\/configuration>/ s/.*/${escaped_core_conf}&/" $HIVE_HOME/conf/hive-site.xml

RUN core_conf="<property><name>hadoop.proxyuser.${DEFAULT_USER}.hosts</name><value>*</value></property>\
            <property><name>hadoop.proxyuser.${DEFAULT_USER}.groups</name><value>*</value></property>" \
    && escaped_core_conf=$(echo $core_conf | sed 's/\//\\\//g') \
    && sed -i "/<\/configuration>/ s/.*/${escaped_core_conf}&/" $HADOOP_CONF_DIR/core-site.xml

    
# == Install ============================
ARG FLINK_VERSION=2.1.0
ENV FLINK_HOME=/home/${DEFAULT_USER}/flink-${FLINK_VERSION}

RUN set -x \
    && DOWNLOAD_URL="https://dlcdn.apache.org/flink/flink-${FLINK_VERSION}/flink-${FLINK_VERSION}-bin-scala_2.12.tgz" \
    && curl -fSL "$DOWNLOAD_URL" -o download.tar.gz \
    && tar -xvf download.tar.gz \
    && mv flink-${FLINK_VERSION} $FLINK_HOME \
    && rm download.tar.gz

ENV PATH=$PATH:$FLINK_HOME/bin

RUN echo "export HADOOP_CLASSPATH=\$(\$HADOOP_HOME/bin/hadoop classpath)" >> $FLINK_HOME/bin/config.sh \
    && cd $FLINK_HOME/lib \
#    && curl -O "https://repo1.maven.org/maven2/org/apache/flink/flink-sql-connector-hive-3.1.3_2.12/${FLINK_VERSION}/flink-sql-connector-hive-3.1.3_2.12-${FLINK_VERSION}.jar" \
    && cp ../opt/flink-sql-*.jar ./ \
    && sed -i "s/# port: 8081/port: 8083/" $FLINK_HOME/conf/*.yaml \
    && sed -i "s/bind-address: localhost/bind-address: 0.0.0.0/" $FLINK_HOME/conf/*.yaml

COPY docker-entrypoint.sh /

WORKDIR ${FLINK_HOME}

EXPOSE 6123 8083

ENTRYPOINT ["/docker-entrypoint.sh"]
